package com.avasthi.datascience.pipeline.jobs;

/**
 * Hello world!
 *
 */
public class JobMain
{
    public static void main( String[] args ) {

      /*  String query = "(select * from user as u limit 100) user";
        SparkContextManager scm = new SparkContextManager("Test Job", "spark://192.168.1.105:7077");
        Dataset<Row> dataSetRow = scm.executeQuery(url, query, "cprime", "cprime123");
        StructType st = dataSetRow.schema();
        for (StructField sf : st.fields()) {
            System.out.println(String.format("=======%s, %s, %s", sf.name(), sf.dataType(), sf.metadata().toString()));
        }
        System.out.println("SQL is " +st.sql());
        dataSetRow.show();
        System.out.println( "Hello World!" );
        System.exit(0);*/
    }
}
